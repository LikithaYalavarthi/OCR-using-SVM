{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7zppyfLx5SJm"
   },
   "source": [
    "SVM is a Constrained Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNew1Qf25SJn"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UNIb5uG5SJt",
    "outputId": "09403e4d-d365-44ce-efe6-29dc44e6e49f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
      "0          T     2     8      3       5      1     8    13      0      6   \n",
      "1          I     5    12      3       7      2    10     5      5      4   \n",
      "2          D     4    11      6       8      6    10     6      2      6   \n",
      "3          N     7    11      6       6      3     5     9      4      6   \n",
      "4          G     2     1      3       1      1     8     6      6      6   \n",
      "5          S     4    11      5       8      3     8     8      6      9   \n",
      "6          B     4     2      5       4      4     8     7      6      6   \n",
      "7          A     1     1      3       2      1     8     2      2      2   \n",
      "8          J     2     2      4       4      2    10     6      2      6   \n",
      "9          M    11    15     13       9      7    13     2      6      2   \n",
      "10         X     3     9      5       7      4     8     7      3      8   \n",
      "11         O     6    13      4       7      4     6     7      6      3   \n",
      "12         G     4     9      6       7      6     7     8      6      2   \n",
      "13         M     6     9      8       6      9     7     8      6      5   \n",
      "14         R     5     9      5       7      6     6    11      7      3   \n",
      "15         F     6     9      5       4      3    10     6      3      5   \n",
      "16         O     3     4      4       3      2     8     7      7      5   \n",
      "17         C     7    10      5       5      2     6     8      6      8   \n",
      "18         T     6    11      6       8      5     6    11      5      6   \n",
      "19         J     2     2      3       3      1    10     6      3      6   \n",
      "20         J     1     3      2       2      1     8     8      2      5   \n",
      "21         H     4     5      5       4      4     7     7      6      6   \n",
      "22         S     3     2      3       3      2     8     8      7      5   \n",
      "23         O     6    11      7       8      5     7     6      9      6   \n",
      "24         J     3     6      4       4      2     6     6      4      4   \n",
      "25         C     6    11      7       8      3     7     8      7     11   \n",
      "26         M     7    11     11       8      9     3     8      4      5   \n",
      "27         W    12    14     12       8      5     9    10      4      3   \n",
      "28         H     6     9      8       7      6     8     6      6      7   \n",
      "29         G     3     6      4       4      2     6     6      5      5   \n",
      "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
      "19970      F     7    10      9       8      7     9     7      2      6   \n",
      "19971      C     5    10      7       9      8     5     6      4      4   \n",
      "19972      V     4     7      6       5      6     8     6      4      2   \n",
      "19973      T     4     4      5       3      2     5    12      2      8   \n",
      "19974      N     5     9      5       4      2     9    11      5      3   \n",
      "19975      E     1     0      1       0      0     5     8      5      7   \n",
      "19976      L     3     8      3       6      2     0     2      4      6   \n",
      "19977      A     3     9      5       6      2     6     5      3      1   \n",
      "19978      K     5    11      5       8      5     3     8      7      3   \n",
      "19979      M     6     9     10       7     12     7     5      3      2   \n",
      "19980      R     2     3      3       2      2     7     7      5      5   \n",
      "19981      S     6    12      6       7      3     6     8      3      6   \n",
      "19982      Y     3     9      5       6      3     7     9      1      6   \n",
      "19983      V     7    10      5       5      2     6    11      5      4   \n",
      "19984      S     2     0      2       1      1     8     7      4      6   \n",
      "19985      M     5     6      8       4      5     9     6      2      4   \n",
      "19986      O     9    15      6       8      5     5     7      7      4   \n",
      "19987      L     3     7      3       5      1     0     1      6      6   \n",
      "19988      D     6     9      8       8      8     7     6      5      7   \n",
      "19989      P     2     1      3       2      1     4    10      3      5   \n",
      "19990      W     3     8      5       6      5    11    11      2      2   \n",
      "19991      O     4     3      5       4      2     7     6      8      8   \n",
      "19992      E     4     9      5       6      3     5     9      2     10   \n",
      "19993      J     2    11      3       8      2    15     4      4      5   \n",
      "19994      T     5     8      7       7      7     7     9      4      8   \n",
      "19995      D     2     2      3       3      2     7     7      7      6   \n",
      "19996      C     7    10      8       8      4     4     8      6      9   \n",
      "19997      T     6     9      6       7      5     6    11      3      7   \n",
      "19998      S     2     3      4       2      1     8     7      2      6   \n",
      "19999      A     4     9      6       6      2     9     5      3      1   \n",
      "\n",
      "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
      "0          6      10       8      0       8      0       8  \n",
      "1         13       3       9      2       8      4      10  \n",
      "2         10       3       7      3       7      3       9  \n",
      "3          4       4      10      6      10      2       8  \n",
      "4          6       5       9      1       7      5      10  \n",
      "5          5       6       6      0       8      9       7  \n",
      "6          7       6       6      2       8      7      10  \n",
      "7          8       2       8      1       6      2       7  \n",
      "8         12       4       8      1       6      1       7  \n",
      "9         12       1       9      8       1      1       8  \n",
      "10         5       6       8      2       8      6       7  \n",
      "11        10       7       9      5       9      5       8  \n",
      "12         6       5      11      4       8      7       8  \n",
      "13         7       5       8      8       9      8       6  \n",
      "14         7       3       9      2       7      5      11  \n",
      "15        10       5       7      3       9      6       9  \n",
      "16         7       6       8      2       8      3       8  \n",
      "17        11       7      11      2       8      5       9  \n",
      "18        11       9       4      3      12      2       4  \n",
      "19        12       4       9      0       7      1       7  \n",
      "20        14       5       8      0       7      0       7  \n",
      "21         7       6       8      3       8      3       8  \n",
      "22         7       5       7      2       8      9       8  \n",
      "23         7       5       9      4       8      5       5  \n",
      "24        14       8      12      1       6      1       6  \n",
      "25         4       7      14      1       7      4       8  \n",
      "26        10      11      10     10       9      5       7  \n",
      "27         5      10       7     10      12      2       6  \n",
      "28         7       7       9      6       8      4       8  \n",
      "29         6       6       9      2       8      4       8  \n",
      "...      ...     ...     ...    ...     ...    ...     ...  \n",
      "19970     12       4       6      5       9      4       9  \n",
      "19971      7       6      11      5      11      8      10  \n",
      "19972      7       8       8      7       9      4       6  \n",
      "19973     11       9       4      0      10      2       4  \n",
      "19974      5       6       9      5      11      2       6  \n",
      "19975      7       6      12      0       8      6      10  \n",
      "19976      1       0       8      0       8      0       8  \n",
      "19977      6       1       8      2       7      2       7  \n",
      "19978      6       4      11      3       8      2      11  \n",
      "19979      7       5       8     15       7      4       6  \n",
      "19980      7       5       6      2       7      4       8  \n",
      "19981     13       7       7      2       9      3       7  \n",
      "19982      6      11       8      2      11      2       7  \n",
      "19983     11       9       4      4      11      3      10  \n",
      "19984      5       6       8      0       8      7       8  \n",
      "19985      9       5       7      8       6      2       8  \n",
      "19986     10       7      10      5       9      5       8  \n",
      "19987      0       0       6      0       8      0       8  \n",
      "19988      7       5       9      6       5     10       3  \n",
      "19989     10       8       5      0       9      3       7  \n",
      "19990      5       8       7      7      12      1       7  \n",
      "19991      6       5       7      3       8      4       8  \n",
      "19992     10       8       9      2       8      5       5  \n",
      "19993     13       1       8      0       7      0       8  \n",
      "19994      7       7       8      3      10      8       6  \n",
      "19995      6       6       4      2       8      3       7  \n",
      "19996     12       9      13      2       9      3       7  \n",
      "19997     11       9       5      2      12      2       4  \n",
      "19998     10       6       8      1       9      5       8  \n",
      "19999      8       1       8      2       7      2       8  \n",
      "\n",
      "[20000 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "url = \"D:/ML_dataScience/batches/ZenRays/exercises/letterdata.csv\"\n",
    "dataset = pandas.read_csv(url)\n",
    "dataset.shape\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tGjtyOxV5SJw",
    "outputId": "9432a898-faad-497f-eee5-e071ef49af9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.13333333  0.53333333  0.2        ...,  0.53333333  0.          0.53333333]\n",
      " [ 0.33333333  0.8         0.2        ...,  0.53333333  0.26666667\n",
      "   0.66666667]\n",
      " [ 0.26666667  0.73333333  0.4        ...,  0.46666667  0.2         0.6       ]\n",
      " ..., \n",
      " [ 0.4         0.6         0.4        ...,  0.8         0.13333333\n",
      "   0.26666667]\n",
      " [ 0.13333333  0.2         0.26666667 ...,  0.6         0.33333333\n",
      "   0.53333333]\n",
      " [ 0.26666667  0.6         0.4        ...,  0.46666667  0.13333333\n",
      "   0.53333333]]\n",
      "               xbox          ybox         width       height         onpix  \\\n",
      "count  20000.000000  20000.000000  20000.000000  20000.00000  20000.000000   \n",
      "mean       4.023550      7.035500      5.121850      5.37245      3.505850   \n",
      "std        1.913212      3.304555      2.014573      2.26139      2.190458   \n",
      "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
      "25%        3.000000      5.000000      4.000000      4.00000      2.000000   \n",
      "50%        4.000000      7.000000      5.000000      6.00000      3.000000   \n",
      "75%        5.000000      9.000000      6.000000      7.00000      5.000000   \n",
      "max       15.000000     15.000000     15.000000     15.00000     15.000000   \n",
      "\n",
      "               xbar          ybar         x2bar         y2bar         xybar  \\\n",
      "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
      "mean       6.897600      7.500450      4.628600      5.178650      8.282050   \n",
      "std        2.026035      2.325354      2.699968      2.380823      2.488475   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        6.000000      6.000000      3.000000      4.000000      7.000000   \n",
      "50%        7.000000      7.000000      4.000000      5.000000      8.000000   \n",
      "75%        8.000000      9.000000      6.000000      7.000000     10.000000   \n",
      "max       15.000000     15.000000     15.000000     15.000000     15.000000   \n",
      "\n",
      "            x2ybar        xy2bar         xedge        xedgey         yedge  \\\n",
      "count  20000.00000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
      "mean       6.45400      7.929000      3.046100      8.338850      3.691750   \n",
      "std        2.63107      2.080619      2.332541      1.546722      2.567073   \n",
      "min        0.00000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        5.00000      7.000000      1.000000      8.000000      2.000000   \n",
      "50%        6.00000      8.000000      3.000000      8.000000      3.000000   \n",
      "75%        8.00000      9.000000      4.000000      9.000000      5.000000   \n",
      "max       15.00000     15.000000     15.000000     15.000000     15.000000   \n",
      "\n",
      "            yedgex  \n",
      "count  20000.00000  \n",
      "mean       7.80120  \n",
      "std        1.61747  \n",
      "min        0.00000  \n",
      "25%        7.00000  \n",
      "50%        8.00000  \n",
      "75%        9.00000  \n",
      "max       15.00000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smoitra.ORADEV\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "print(minmax_scale(dataset.values[:,1:17]))\n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xtta7Yj65SJw",
    "outputId": "f7266281-a75d-425a-80fa-b7da247c398b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 8 3 ..., 8 0 8]\n",
      " [5 12 3 ..., 8 4 10]\n",
      " [4 11 6 ..., 7 3 9]\n",
      " ..., \n",
      " [6 9 6 ..., 12 2 4]\n",
      " [2 3 4 ..., 9 5 8]\n",
      " [4 9 6 ..., 7 2 8]]\n",
      "[['T']\n",
      " ['I']\n",
      " ['D']\n",
      " ..., \n",
      " ['T']\n",
      " ['S']\n",
      " ['A']]\n"
     ]
    }
   ],
   "source": [
    "# Split into Train-Test\n",
    "array = dataset.values\n",
    "#print(array)\n",
    "X = array[:,1:17]\n",
    "Y = array[:,0:1]\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6v5zlQmD5SJw",
    "outputId": "bbfa20ec-7aad-489f-8932-c1ba1f2f4ad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 5 6 ..., 7 2 8]\n",
      " [5 11 6 ..., 9 1 8]\n",
      " [3 1 3 ..., 8 6 9]\n",
      " ..., \n",
      " [6 10 9 ..., 8 4 7]\n",
      " [4 7 6 ..., 8 4 6]\n",
      " [2 3 3 ..., 9 9 8]]\n",
      "[['A']\n",
      " ['J']\n",
      " ['B']\n",
      " ..., \n",
      " ['X']\n",
      " ['U']\n",
      " ['S']]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vX4iz07p5SJw",
    "outputId": "6c10f1d6-8bc6-4bdc-f946-6f1f34cacdfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smoitra.ORADEV\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of default SVM:\n",
      "0.9735\n",
      "\n",
      "confusion_matrix of default SVM:\n",
      "[[136   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   1   0]\n",
      " [  0 160   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0 124   0   1   0   0   0   0   0   0   0   0   0   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 156   0   0   0   0   0   0   0   0   0   1   1   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 161   0   6   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   3]\n",
      " [  0   0   0   0   0 163   0   1   0   0   0   0   0   0   0   2   0   0\n",
      "    1   3   0   0   0   1   0   0]\n",
      " [  0   0   0   0   2   0 154   1   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   1 141   0   0   3   0   0   0   0   0   0   7\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 150   8   0   0   0   1   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 139   0   0   0   0   1   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   3   0   0 148   0   0   0   0   0   0   3\n",
      "    0   0   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1 154   0   0   0   0   0   1\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0 185   1   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0 161   1   0   0   3\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   3   2   0   0   0   0   0   0   0   0   0   0 151   0   0   0\n",
      "    0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0 162   0   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0 139   0\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   2   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0 135\n",
      "    0   0   0   0   0   0   0   0]\n",
      " [  0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  144   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0 138   0   0   0   0   1   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 156   0   0   0   0   0]\n",
      " [  0   8   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0\n",
      "    0   0   0 131   0   0   3   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0   0   0 160   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   1   0   0   0 153   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   1   0   0   0 145   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   0\n",
      "    0   0   0   0   0   0   0 148]]\n",
      "\n",
      "classification_report of default SVM:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          A       0.99      0.99      0.99       137\n",
      "          B       0.93      0.99      0.96       162\n",
      "          C       0.98      0.98      0.98       127\n",
      "          D       0.97      0.99      0.98       158\n",
      "          E       0.98      0.95      0.96       170\n",
      "          F       0.98      0.95      0.97       171\n",
      "          G       0.94      0.98      0.96       157\n",
      "          H       0.96      0.92      0.94       153\n",
      "          I       1.00      0.94      0.97       159\n",
      "          J       0.95      0.99      0.97       140\n",
      "          K       0.97      0.95      0.96       155\n",
      "          L       1.00      0.99      0.99       156\n",
      "          M       0.99      0.99      0.99       187\n",
      "          N       0.98      0.97      0.97       166\n",
      "          O       0.95      0.96      0.96       157\n",
      "          P       0.98      0.99      0.98       164\n",
      "          Q       0.99      0.98      0.98       142\n",
      "          R       0.89      0.97      0.93       139\n",
      "          S       0.99      0.99      0.99       146\n",
      "          T       0.97      0.98      0.98       141\n",
      "          U       0.99      0.99      0.99       157\n",
      "          V       1.00      0.91      0.95       144\n",
      "          W       0.99      0.99      0.99       162\n",
      "          X       0.99      0.99      0.99       154\n",
      "          Y       0.97      0.99      0.98       146\n",
      "          Z       0.98      0.99      0.98       150\n",
      "\n",
      "avg / total       0.97      0.97      0.97      4000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "slack = []\n",
    "slack.append(0.001)\n",
    "slack.append(0.01)\n",
    "slack.append(0.1)\n",
    "slack.append(1)\n",
    "slack.append(10)\n",
    "slack.append(100)\n",
    "SVmodels = []\n",
    "SVMpredictions = []\n",
    "SVMaccuracy = []\n",
    "\n",
    "SVobj = SVC(C=0.001)\n",
    "SVobj.fit(X_train,Y_train)\n",
    "predictions = SVobj.predict(X_validation)\n",
    "acc = accuracy_score(Y_validation, predictions)\n",
    "SVmodels.append(SVobj)\n",
    "SVMpredictions.append(predictions)\n",
    "SVMaccuracy.append(acc)\n",
    "\n",
    "SVobj = SVC(C=0.01)\n",
    "SVobj.fit(X_train,Y_train)\n",
    "predictions = SVobj.predict(X_validation)\n",
    "acc = accuracy_score(Y_validation, predictions)\n",
    "SVmodels.append(SVobj)\n",
    "SVMpredictions.append(predictions)\n",
    "SVMaccuracy.append(acc)\n",
    "\n",
    "SVobj = SVC(C=0.1)\n",
    "SVobj.fit(X_train,Y_train)\n",
    "predictions = SVobj.predict(X_validation)\n",
    "acc = accuracy_score(Y_validation, predictions)\n",
    "SVmodels.append(SVobj)\n",
    "SVMpredictions.append(predictions)\n",
    "SVMaccuracy.append(acc)\n",
    "\n",
    "SVobj = SVC(C=1)\n",
    "SVobj.fit(X_train,Y_train)\n",
    "predictions = SVobj.predict(X_validation)\n",
    "acc = accuracy_score(Y_validation, predictions)\n",
    "SVmodels.append(SVobj)\n",
    "SVMpredictions.append(predictions)\n",
    "SVMaccuracy.append(acc)\n",
    "#show metrics for default SVM\n",
    "print(\"Accuracy score of default SVM:\")\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print()\n",
    "\n",
    "print(\"confusion_matrix of default SVM:\")\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print()\n",
    "\n",
    "print(\"classification_report of default SVM:\")\n",
    "print(classification_report(Y_validation, predictions))\n",
    "print()\n",
    "\n",
    "SVobj = SVC(C=10)\n",
    "SVobj.fit(X_train,Y_train)\n",
    "predictions = SVobj.predict(X_validation)\n",
    "acc = accuracy_score(Y_validation, predictions)\n",
    "SVmodels.append(SVobj)\n",
    "SVMpredictions.append(predictions)\n",
    "SVMaccuracy.append(acc)\n",
    "\n",
    "SVobj = SVC(C=100)\n",
    "SVobj.fit(X_train,Y_train)\n",
    "predictions = SVobj.predict(X_validation)\n",
    "acc = accuracy_score(Y_validation, predictions)\n",
    "SVmodels.append(SVobj)\n",
    "SVMpredictions.append(predictions)\n",
    "SVMaccuracy.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymd-7YMH5SKA",
    "outputId": "ddfee660-3b6d-4982-bcf0-2bd1f571abd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM\n",
      "[0.03925, 0.125, 0.90425, 0.97350000000000003, 0.97650000000000003, 0.97650000000000003]\n",
      "\n",
      "Slack for SVM\n",
      "[0.001, 0.01, 0.1, 1, 10, 100]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of SVM\")\n",
    "print(SVMaccuracy)\n",
    "print()\n",
    "\n",
    "print(\"Slack for SVM\")\n",
    "print(slack)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4aa54uQR5SKA",
    "outputId": "cb79fe10-dcd2-4d19-c735-8e9c08730a44"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14fe6d68>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(slack,SVMaccuracy)\n",
    "plt.ylabel(\"SVM accuracy\")\n",
    "plt.xlabel(\"C=slack\")\n",
    "plt.ylim(0,1)\n",
    "plt.xlim(0,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XrksMpYi5SKA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "SVM_OCR.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
